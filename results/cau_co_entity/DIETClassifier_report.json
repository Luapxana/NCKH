{
  "tiet": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 5,
    "confused_with": {}
  },
  "drl": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 5,
    "confused_with": {}
  },
  "pass_credit": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 2,
    "confused_with": {
      "credit": 2
    }
  },
  "diemchu": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 4,
    "confused_with": {}
  },
  "debt": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 5,
    "confused_with": {}
  },
  "gpa": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6,
    "confused_with": {}
  },
  "diemso": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 3,
    "confused_with": {}
  },
  "credit": {
    "precision": 0.6,
    "recall": 1.0,
    "f1-score": 0.7499999999999999,
    "support": 3,
    "confused_with": {}
  },
  "year": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 26,
    "confused_with": {}
  },
  "micro avg": {
    "precision": 0.9661016949152542,
    "recall": 0.9661016949152542,
    "f1-score": 0.9661016949152542,
    "support": 59
  },
  "macro avg": {
    "precision": 0.8444444444444444,
    "recall": 0.8888888888888888,
    "f1-score": 0.8611111111111112,
    "support": 59
  },
  "weighted avg": {
    "precision": 0.9457627118644067,
    "recall": 0.9661016949152542,
    "f1-score": 0.9533898305084746,
    "support": 59
  },
  "accuracy": 0.992619926199262
}