{
  "provide_debt": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 5,
    "confused_with": {}
  },
  "provide_gpa": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6,
    "confused_with": {}
  },
  "thoi_gian_tung_tiet_hoc": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 5,
    "confused_with": {}
  },
  "diemchu": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 3,
    "confused_with": {}
  },
  "provide_year": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 12,
    "confused_with": {}
  },
  "provide_drl": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 5,
    "confused_with": {}
  },
  "provide_credit": {
    "precision": 0.75,
    "recall": 1.0,
    "f1-score": 0.8571428571428571,
    "support": 3,
    "confused_with": {}
  },
  "provide_pass": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 2,
    "confused_with": {
      "so_tiet_moi_tin_chi": 1,
      "provide_credit": 1
    }
  },
  "doi_diem": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 4,
    "confused_with": {}
  },
  "micro avg": {
    "precision": 0.9772727272727273,
    "recall": 0.9555555555555556,
    "f1-score": 0.9662921348314608,
    "support": 45
  },
  "macro avg": {
    "precision": 0.8611111111111112,
    "recall": 0.8888888888888888,
    "f1-score": 0.873015873015873,
    "support": 45
  },
  "weighted avg": {
    "precision": 0.9388888888888889,
    "recall": 0.9555555555555556,
    "f1-score": 0.946031746031746,
    "support": 45
  },
  "accuracy": 0.9555555555555556
}